{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zD3oep91JWN4",
        "outputId": "523fd669-074d-4bc8-b1d5-83421574b19e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement scipy.io (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for scipy.io\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting reformer_pytorch\n",
            "  Downloading reformer_pytorch-1.4.4-py3-none-any.whl (16 kB)\n",
            "Collecting axial-positional-embedding>=0.1.0 (from reformer_pytorch)\n",
            "  Downloading axial_positional_embedding-0.2.1.tar.gz (2.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting einops (from reformer_pytorch)\n",
            "  Downloading einops-0.8.0-py3-none-any.whl (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting local-attention (from reformer_pytorch)\n",
            "  Downloading local_attention-1.9.1-py3-none-any.whl (8.2 kB)\n",
            "Collecting product-key-memory (from reformer_pytorch)\n",
            "  Downloading product_key_memory-0.2.10-py3-none-any.whl (6.4 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from reformer_pytorch) (2.2.1+cu121)\n",
            "Collecting colt5-attention>=0.10.14 (from product-key-memory->reformer_pytorch)\n",
            "  Downloading CoLT5_attention-0.10.20-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->reformer_pytorch) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->reformer_pytorch) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->reformer_pytorch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->reformer_pytorch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->reformer_pytorch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->reformer_pytorch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->reformer_pytorch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->reformer_pytorch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->reformer_pytorch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->reformer_pytorch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->reformer_pytorch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->reformer_pytorch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->reformer_pytorch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->reformer_pytorch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->reformer_pytorch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch->reformer_pytorch)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->reformer_pytorch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->reformer_pytorch) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->reformer_pytorch)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from colt5-attention>=0.10.14->product-key-memory->reformer_pytorch) (24.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->reformer_pytorch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->reformer_pytorch) (1.3.0)\n",
            "Building wheels for collected packages: axial-positional-embedding\n",
            "  Building wheel for axial-positional-embedding (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for axial-positional-embedding: filename=axial_positional_embedding-0.2.1-py3-none-any.whl size=2882 sha256=27d9e0cc5e170ea9db36db1d54c7f4b018e46a3d4aac51eeb0b4656e92f917da\n",
            "  Stored in directory: /root/.cache/pip/wheels/b1/cb/39/7ce7ff2d2fd37cfe1fe7b3a3c43cf410632b2ad3b3f3986d73\n",
            "Successfully built axial-positional-embedding\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, einops, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, local-attention, axial-positional-embedding, colt5-attention, product-key-memory, reformer_pytorch\n",
            "Successfully installed axial-positional-embedding-0.2.1 colt5-attention-0.10.20 einops-0.8.0 local-attention-1.9.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 product-key-memory-0.2.10 reformer_pytorch-1.4.4\n",
            "Collecting mamba-ssm\n",
            "  Downloading mamba_ssm-1.2.0.post1.tar.gz (34 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from mamba-ssm) (2.2.1+cu121)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mamba-ssm) (24.0)\n",
            "Collecting ninja (from mamba-ssm)\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from mamba-ssm) (0.8.0)\n",
            "Requirement already satisfied: triton in /usr/local/lib/python3.10/dist-packages (from mamba-ssm) (2.2.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from mamba-ssm) (4.40.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (12.1.105)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->mamba-ssm) (12.4.127)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm) (1.25.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm) (4.66.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->mamba-ssm) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->mamba-ssm) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->mamba-ssm) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->mamba-ssm) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->mamba-ssm) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->mamba-ssm) (1.3.0)\n",
            "Building wheels for collected packages: mamba-ssm\n",
            "  Building wheel for mamba-ssm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mamba-ssm: filename=mamba_ssm-1.2.0.post1-cp310-cp310-linux_x86_64.whl size=137750683 sha256=b264292652a34fb9dd0ce880a34a4407ba7256a3338388d056769ec29a4581c9\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/6e/60/ddd5c574b5793a30028f2cabdacd2a3ec2276edaaa8c00fd35\n",
            "Successfully built mamba-ssm\n",
            "Installing collected packages: ninja, mamba-ssm\n",
            "Successfully installed mamba-ssm-1.2.0.post1 ninja-1.11.1.1\n",
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive\n",
            "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: './requirements.txt'\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install pydub\n",
        "!pip install scipy.io\n",
        "!pip install reformer_pytorch\n",
        "!pip install mamba-ssm\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "from pydub import AudioSegment\n",
        "from scipy.io import wavfile\n",
        "import numpy as np\n",
        "import io\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd /content/drive/MyDrive/\n",
        "#!git clone https://github.com/wzhwzhwzh0921/S-D-Mamba\n",
        "!pip install -r ./requirements.txt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "vWl_7gTcPVPO",
        "outputId": "9fef9387-0852-44be-c6cd-5d16abefe5a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-2be84f2888ff>:19: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
            "  sample_rate, audio_data = wavfile.read(wav_path)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-2be84f2888ff>\u001b[0m in \u001b[0;36m<cell line: 31>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m#convert_to_wav(directory)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mconvert_to_timeseries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-3-2be84f2888ff>\u001b[0m in \u001b[0;36mconvert_to_timeseries\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mtxt_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./S-D-Mamba/dataset/dopplerdata/\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"doppler.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtxt_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m       \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavetxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtxt_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombined_time_series\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Saved combined time series as {txt_path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36msavetxt\u001b[0;34m(fname, X, fmt, delimiter, newline, header, footer, comments, encoding)\u001b[0m\n\u001b[1;32m   1626\u001b[0m                                     \u001b[0;34m\"format specifier ('%s')\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1627\u001b[0m                                     % (str(X.dtype), format)) from e\n\u001b[0;32m-> 1628\u001b[0;31m                 \u001b[0mfh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1630\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfooter\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "def convert_to_wav(directory):\n",
        "    for filename in os.listdir(directory):\n",
        "        if filename.endswith(\".mp3\") or filename.endswith(\".m4a\"):\n",
        "            input_path = os.path.join(directory, filename)\n",
        "            output_path = os.path.join(directory, os.path.splitext(filename)[0] + \".wav\")\n",
        "            audio = AudioSegment.from_file(input_path)\n",
        "            audio.export(output_path, format=\"wav\")\n",
        "            os.remove(input_path)\n",
        "\n",
        "            print(f\"Converted {filename} to WAV.\")\n",
        "\n",
        "def convert_to_timeseries(directory):\n",
        "    os.makedirs(\"./S-D-Mamba/dataset/dopplerdata/\", exist_ok=True)\n",
        "    time_series_data = []\n",
        "\n",
        "    for filename in os.listdir(directory):\n",
        "        if filename.endswith(\".wav\"):\n",
        "            wav_path = os.path.join(directory, filename)\n",
        "            sample_rate, audio_data = wavfile.read(wav_path)\n",
        "            time_series_data.append(audio_data.flatten())\n",
        "\n",
        "    combined_time_series = np.concatenate(time_series_data)\n",
        "    txt_path = os.path.join(\"./S-D-Mamba/dataset/dopplerdata/\", \"doppler.txt\")\n",
        "    with io.open(txt_path, 'w', encoding='utf-8') as file:\n",
        "      np.savetxt(txt_path, combined_time_series, delimiter=\",\")\n",
        "    print(f\"Saved combined time series as {txt_path}\")\n",
        "\n",
        "directory = './dopplerdata/'\n",
        "\n",
        "#convert_to_wav(directory)\n",
        "convert_to_timeseries(directory)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def convert_to_csv(directory):\n",
        "    os.makedirs(\"./S-D-Mamba/dataset/dopplerdata/\", exist_ok=True)\n",
        "    time_series_data = []\n",
        "\n",
        "    for filename in os.listdir(directory):\n",
        "        if filename.endswith(\".wav\"):\n",
        "            wav_path = os.path.join(directory, filename)\n",
        "            sample_rate, audio_data = wavfile.read(wav_path)\n",
        "            audio_data = audio_data.flatten()\n",
        "\n",
        "            # Save each WAV file as a separate CSV file\n",
        "            csv_filename = os.path.splitext(filename)[0] + \".csv\"\n",
        "            csv_path = os.path.join(\"./S-D-Mamba/dataset/dopplerdata/\", csv_filename)\n",
        "            pd.DataFrame(audio_data).to_csv(csv_path, index=False, header=False)\n",
        "            print(f\"Saved individual CSV file as {csv_path}\")\n",
        "            time_series_data.append(audio_data)\n",
        "\n",
        "    combined_time_series = np.concatenate(time_series_data)\n",
        "\n",
        "    # Convert the data type to a more compact representation (e.g., int16 or float32)\n",
        "    combined_time_series = combined_time_series.astype(np.int16)\n",
        "\n",
        "    combined_csv_path = os.path.join(\"./S-D-Mamba/dataset/dopplerdata/\", \"doppler_combined.csv\")\n",
        "    pd.DataFrame(combined_time_series).to_csv(combined_csv_path, index=False, header=False)\n",
        "\n",
        "    print(f\"Saved individual CSV files and combined time series as {combined_csv_path}\")\n",
        "\n",
        "directory = './dopplerdata/'\n",
        "convert_to_csv(directory)"
      ],
      "metadata": {
        "id": "Uws5wKFjAsxv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fef12b9a-8df9-4444-863a-5e8dd08cddae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-a5b4f0aa6c79>:10: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
            "  sample_rate, audio_data = wavfile.read(wav_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved individual CSV file as ./S-D-Mamba/dataset/dopplerdata/FULLSetMixed.csv\n",
            "Saved individual CSV file as ./S-D-Mamba/dataset/dopplerdata/04 - Working With Nihilism - Dopplerhaus.csv\n",
            "Saved individual CSV file as ./S-D-Mamba/dataset/dopplerdata/02 - Faustian Deal - Dopplerhaus.csv\n",
            "Saved individual CSV file as ./S-D-Mamba/dataset/dopplerdata/Via Coober Pedy Master 24bit48kHz.csv\n",
            "Saved individual CSV file as ./S-D-Mamba/dataset/dopplerdata/FINAL EP REHEARSAL_20.03.23.csv\n",
            "Saved individual CSV file as ./S-D-Mamba/dataset/dopplerdata/EP LAUNCH_WAREHOUSE REHEARSAL_19.03.23.csv\n",
            "Saved individual CSV file as ./S-D-Mamba/dataset/dopplerdata/bergy set rehearsal.csv\n",
            "Saved individual CSV file as ./S-D-Mamba/dataset/dopplerdata/21.2.23Three Phase Rehearsal Studios 9.csv\n",
            "Saved individual CSV file as ./S-D-Mamba/dataset/dopplerdata/EP LAUNCH REHEARSAL_16.03.23.csv\n",
            "Saved individual CSV file as ./S-D-Mamba/dataset/dopplerdata/catholic core.csv\n",
            "Saved individual CSV file as ./S-D-Mamba/dataset/dopplerdata/cool Luke riff.csv\n",
            "Saved individual CSV file as ./S-D-Mamba/dataset/dopplerdata/5 divided by four.csv\n",
            "Saved individual CSV file as ./S-D-Mamba/dataset/dopplerdata/24aug jimmy1.csv\n",
            "Saved individual CSV file as ./S-D-Mamba/dataset/dopplerdata/ambient.csv\n",
            "Saved individual CSV file as ./S-D-Mamba/dataset/dopplerdata/24aug jimmy2.csv\n",
            "Saved individual CSV file as ./S-D-Mamba/dataset/dopplerdata/24aug CDXX.csv\n",
            "Saved individual CSV file as ./S-D-Mamba/dataset/dopplerdata/15june4.csv\n",
            "Saved individual CSV file as ./S-D-Mamba/dataset/dopplerdata/15junephridge.csv\n",
            "Saved individual CSV file as ./S-D-Mamba/dataset/dopplerdata/15june3.csv\n",
            "Saved individual CSV file as ./S-D-Mamba/dataset/dopplerdata/009.csv\n",
            "Saved individual CSV file as ./S-D-Mamba/dataset/dopplerdata/15june5.csv\n",
            "Saved individual CSV file as ./S-D-Mamba/dataset/dopplerdata/004.csv\n",
            "Saved individual CSV file as ./S-D-Mamba/dataset/dopplerdata/Copy of praclatenov.csv\n",
            "Saved individual CSV file as ./S-D-Mamba/dataset/dopplerdata/Finalrecordingfashion.csv\n",
            "Saved individual CSV file as ./S-D-Mamba/dataset/dopplerdata/eMastered_LGA_BERGY_06-03-23.csv\n",
            "Saved individual CSV file as ./S-D-Mamba/dataset/dopplerdata/bergy_14.07.22.csv\n",
            "Saved individual CSV file as ./S-D-Mamba/dataset/dopplerdata/CATHOLIC.csv\n",
            "Saved individual CSV file as ./S-D-Mamba/dataset/dopplerdata/BOOMBAPBOOMBAPDemo4.11.23.csv\n",
            "Saved individual CSV file as ./S-D-Mamba/dataset/dopplerdata/BERGY 30 min set4.11.23.csv\n",
            "Saved individual CSV file as ./S-D-Mamba/dataset/dopplerdata/01 BeatyMcBeat_DEMO.csv\n",
            "Saved individual CSV file as ./S-D-Mamba/dataset/dopplerdata/FUNKY ARLO_NO VOX.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnI6Ru95v3QP",
        "outputId": "b6fa1c53-75d1-4ee0-946a-9f28cef24fc6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: './drive/MyDrive/S-D-Mamba/'\n",
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z7ien60SKWeC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afa29a46-bf6f-444e-b2ca-48c37e83e718"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: './S-D-Mamba/'\n",
            "/content/drive/MyDrive/S-D-Mamba\n",
            "Args in experiment:\n",
            "Namespace(is_training=1, model_id='doppler_96_720', model='S_Mamba', data='doppler', root_path='./dataset/dopplerdata/', data_path='BOOMBAPBOOMBAPDemo4.11.23.csv', features='S', target='0', freq='s', checkpoints='./checkpoints/', seq_len=441000, label_len=48, pred_len=441000, enc_in=137, dec_in=137, c_out=137, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=512, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='MSE', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', exp_name='MTSF', channel_independence=False, inverse=False, class_strategy='projection', target_root_path='./data/electricity/', target_data_path='electricity.csv', efficient_training=False, use_norm=True, partial_start_index=0, d_state=32)\n",
            "Use GPU: cuda:0\n",
            ">>>>>>>start training : doppler_96_720_S_Mamba_doppler_S_ft441000_sl48_ll441000_pl512_dm8_nh2_el1_dl512_df1_fctimeF_ebTrue_dtExp_projection_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "train 11962340\n",
            "val 1393906\n",
            "test 3228812\n",
            "\titers: 100, epoch: 1 | loss: 1.0141253\n",
            "\tspeed: 0.2313s/iter; left time: 864747.4463s\n",
            "\titers: 200, epoch: 1 | loss: 1.0187385\n",
            "\tspeed: 0.1720s/iter; left time: 643119.7909s\n",
            "\titers: 300, epoch: 1 | loss: 1.0106046\n",
            "\tspeed: 0.1753s/iter; left time: 655352.9675s\n",
            "\titers: 400, epoch: 1 | loss: 0.9627708\n",
            "\tspeed: 0.1765s/iter; left time: 659881.8641s\n",
            "\titers: 500, epoch: 1 | loss: 1.0043952\n",
            "\tspeed: 0.1765s/iter; left time: 659583.0004s\n",
            "\titers: 600, epoch: 1 | loss: 1.0097910\n",
            "\tspeed: 0.1836s/iter; left time: 686173.4774s\n",
            "\titers: 700, epoch: 1 | loss: 0.9775981\n",
            "\tspeed: 0.1778s/iter; left time: 664701.1340s\n",
            "\titers: 800, epoch: 1 | loss: 0.9810168\n",
            "\tspeed: 0.1808s/iter; left time: 675865.5670s\n",
            "\titers: 900, epoch: 1 | loss: 0.9909397\n",
            "\tspeed: 0.1808s/iter; left time: 675579.5537s\n",
            "\titers: 1000, epoch: 1 | loss: 1.0246916\n",
            "\tspeed: 0.1795s/iter; left time: 670658.7976s\n",
            "\titers: 1100, epoch: 1 | loss: 1.0005673\n",
            "\tspeed: 0.1821s/iter; left time: 680458.5211s\n",
            "\titers: 1200, epoch: 1 | loss: 1.0246252\n",
            "\tspeed: 0.1817s/iter; left time: 678898.9753s\n",
            "\titers: 1300, epoch: 1 | loss: 1.0397792\n",
            "\tspeed: 0.1798s/iter; left time: 671968.2099s\n",
            "\titers: 1400, epoch: 1 | loss: 1.0047299\n",
            "\tspeed: 0.1820s/iter; left time: 679987.8060s\n",
            "\titers: 1500, epoch: 1 | loss: 1.0426540\n",
            "\tspeed: 0.1822s/iter; left time: 680904.1161s\n",
            "\titers: 1600, epoch: 1 | loss: 1.0127176\n",
            "\tspeed: 0.1799s/iter; left time: 672157.3684s\n",
            "\titers: 1700, epoch: 1 | loss: 0.9850703\n",
            "\tspeed: 0.1848s/iter; left time: 690399.1357s\n",
            "\titers: 1800, epoch: 1 | loss: 1.0372670\n",
            "\tspeed: 0.1808s/iter; left time: 675684.2490s\n",
            "\titers: 1900, epoch: 1 | loss: 0.9847835\n",
            "\tspeed: 0.1826s/iter; left time: 682108.8559s\n",
            "\titers: 2000, epoch: 1 | loss: 1.0190432\n",
            "\tspeed: 0.1791s/iter; left time: 669034.5324s\n",
            "\titers: 2100, epoch: 1 | loss: 1.0074245\n",
            "\tspeed: 0.1808s/iter; left time: 675343.4306s\n",
            "\titers: 2200, epoch: 1 | loss: 1.0286258\n",
            "\tspeed: 0.1809s/iter; left time: 675976.1642s\n",
            "\titers: 2300, epoch: 1 | loss: 1.0019232\n",
            "\tspeed: 0.1836s/iter; left time: 686096.0594s\n",
            "\titers: 2400, epoch: 1 | loss: 0.9952964\n",
            "\tspeed: 0.1789s/iter; left time: 668254.8238s\n",
            "\titers: 2500, epoch: 1 | loss: 1.0060257\n",
            "\tspeed: 0.1815s/iter; left time: 678173.1890s\n",
            "\titers: 2600, epoch: 1 | loss: 0.9742285\n",
            "\tspeed: 0.1821s/iter; left time: 680360.1626s\n",
            "\titers: 2700, epoch: 1 | loss: 1.0719955\n",
            "\tspeed: 0.1849s/iter; left time: 690711.0198s\n",
            "\titers: 2800, epoch: 1 | loss: 0.9997762\n",
            "\tspeed: 0.1883s/iter; left time: 703346.2176s\n",
            "\titers: 2900, epoch: 1 | loss: 1.0096774\n",
            "\tspeed: 0.1814s/iter; left time: 677584.6212s\n",
            "\titers: 3000, epoch: 1 | loss: 1.0150235\n",
            "\tspeed: 0.1828s/iter; left time: 682712.4622s\n",
            "\titers: 3100, epoch: 1 | loss: 1.0047103\n",
            "\tspeed: 0.1808s/iter; left time: 675205.6027s\n",
            "\titers: 3200, epoch: 1 | loss: 0.9929156\n",
            "\tspeed: 0.1821s/iter; left time: 679992.2581s\n",
            "\titers: 3300, epoch: 1 | loss: 1.0162456\n",
            "\tspeed: 0.1809s/iter; left time: 675835.1066s\n",
            "\titers: 3400, epoch: 1 | loss: 0.9674715\n",
            "\tspeed: 0.1875s/iter; left time: 700140.9936s\n",
            "\titers: 3500, epoch: 1 | loss: 1.0014570\n",
            "\tspeed: 0.1828s/iter; left time: 682785.0910s\n",
            "\titers: 3600, epoch: 1 | loss: 1.0187297\n",
            "\tspeed: 0.1822s/iter; left time: 680529.7455s\n",
            "\titers: 3700, epoch: 1 | loss: 0.9858559\n",
            "\tspeed: 0.1834s/iter; left time: 684845.0728s\n",
            "\titers: 3800, epoch: 1 | loss: 0.9896322\n",
            "\tspeed: 0.1826s/iter; left time: 681996.7860s\n",
            "\titers: 3900, epoch: 1 | loss: 1.0026644\n",
            "\tspeed: 0.1876s/iter; left time: 700679.2035s\n",
            "\titers: 4000, epoch: 1 | loss: 1.0072643\n",
            "\tspeed: 0.1839s/iter; left time: 686821.9416s\n",
            "\titers: 4100, epoch: 1 | loss: 1.0151895\n",
            "\tspeed: 0.1857s/iter; left time: 693460.0054s\n",
            "\titers: 4200, epoch: 1 | loss: 0.9959344\n",
            "\tspeed: 0.1831s/iter; left time: 683638.4796s\n",
            "\titers: 4300, epoch: 1 | loss: 0.9962544\n",
            "\tspeed: 0.1843s/iter; left time: 688147.1588s\n",
            "\titers: 4400, epoch: 1 | loss: 1.0382240\n",
            "\tspeed: 0.1849s/iter; left time: 690229.3510s\n",
            "\titers: 4500, epoch: 1 | loss: 1.0162300\n",
            "\tspeed: 0.1891s/iter; left time: 706146.2159s\n",
            "\titers: 4600, epoch: 1 | loss: 0.9943208\n",
            "\tspeed: 0.1836s/iter; left time: 685394.2012s\n",
            "\titers: 4700, epoch: 1 | loss: 0.9893942\n",
            "\tspeed: 0.1855s/iter; left time: 692499.9534s\n",
            "\titers: 4800, epoch: 1 | loss: 1.0073493\n",
            "\tspeed: 0.1860s/iter; left time: 694364.4348s\n",
            "\titers: 4900, epoch: 1 | loss: 0.9914913\n",
            "\tspeed: 0.1847s/iter; left time: 689467.0361s\n",
            "\titers: 5000, epoch: 1 | loss: 1.0121051\n",
            "\tspeed: 0.1851s/iter; left time: 691150.6077s\n",
            "\titers: 5100, epoch: 1 | loss: 0.9947702\n",
            "\tspeed: 0.1844s/iter; left time: 688249.4608s\n",
            "\titers: 5200, epoch: 1 | loss: 1.0202067\n",
            "\tspeed: 0.1861s/iter; left time: 694567.6747s\n",
            "\titers: 5300, epoch: 1 | loss: 0.9894648\n",
            "\tspeed: 0.1823s/iter; left time: 680569.0449s\n",
            "\titers: 5400, epoch: 1 | loss: 0.9989758\n",
            "\tspeed: 0.1819s/iter; left time: 678859.2266s\n",
            "\titers: 5500, epoch: 1 | loss: 1.0154104\n",
            "\tspeed: 0.1851s/iter; left time: 691077.5659s\n",
            "\titers: 5600, epoch: 1 | loss: 1.0086843\n",
            "\tspeed: 0.1830s/iter; left time: 682893.2808s\n",
            "\titers: 5700, epoch: 1 | loss: 0.9651170\n",
            "\tspeed: 0.1825s/iter; left time: 681368.4481s\n",
            "\titers: 5800, epoch: 1 | loss: 0.9961653\n",
            "\tspeed: 0.1832s/iter; left time: 683663.0470s\n",
            "\titers: 5900, epoch: 1 | loss: 1.0084435\n",
            "\tspeed: 0.1850s/iter; left time: 690658.9484s\n",
            "\titers: 6000, epoch: 1 | loss: 0.9962525\n",
            "\tspeed: 0.1826s/iter; left time: 681596.6682s\n",
            "\titers: 6100, epoch: 1 | loss: 0.9844592\n",
            "\tspeed: 0.1811s/iter; left time: 676041.6738s\n",
            "\titers: 6200, epoch: 1 | loss: 1.0072408\n",
            "\tspeed: 0.1886s/iter; left time: 703886.3660s\n",
            "\titers: 6300, epoch: 1 | loss: 1.0062965\n",
            "\tspeed: 0.1843s/iter; left time: 687698.6670s\n",
            "\titers: 6400, epoch: 1 | loss: 0.9948952\n",
            "\tspeed: 0.1832s/iter; left time: 683486.7627s\n",
            "\titers: 6500, epoch: 1 | loss: 1.0297832\n",
            "\tspeed: 0.1817s/iter; left time: 678071.6739s\n",
            "\titers: 6600, epoch: 1 | loss: 1.0109890\n",
            "\tspeed: 0.1859s/iter; left time: 693571.8173s\n",
            "\titers: 6700, epoch: 1 | loss: 1.0494034\n",
            "\tspeed: 0.1839s/iter; left time: 686053.3973s\n",
            "\titers: 6800, epoch: 1 | loss: 1.0024155\n",
            "\tspeed: 0.1828s/iter; left time: 682100.2034s\n",
            "\titers: 6900, epoch: 1 | loss: 1.0415739\n",
            "\tspeed: 0.1833s/iter; left time: 683777.1719s\n",
            "\titers: 7000, epoch: 1 | loss: 1.0080760\n",
            "\tspeed: 0.1842s/iter; left time: 687396.2218s\n",
            "\titers: 7100, epoch: 1 | loss: 1.0008005\n",
            "\tspeed: 0.1831s/iter; left time: 683014.0087s\n",
            "\titers: 7200, epoch: 1 | loss: 0.9856703\n",
            "\tspeed: 0.1831s/iter; left time: 683296.4410s\n",
            "\titers: 7300, epoch: 1 | loss: 1.0291661\n",
            "\tspeed: 0.1914s/iter; left time: 714192.6188s\n",
            "\titers: 7400, epoch: 1 | loss: 1.0066526\n",
            "\tspeed: 0.1829s/iter; left time: 682256.9649s\n",
            "\titers: 7500, epoch: 1 | loss: 0.9710568\n",
            "\tspeed: 0.1818s/iter; left time: 678419.5188s\n",
            "\titers: 7600, epoch: 1 | loss: 1.0049349\n",
            "\tspeed: 0.1817s/iter; left time: 677804.5832s\n",
            "\titers: 7700, epoch: 1 | loss: 0.9979259\n",
            "\tspeed: 0.1846s/iter; left time: 688766.0640s\n",
            "\titers: 7800, epoch: 1 | loss: 0.9958253\n",
            "\tspeed: 0.1834s/iter; left time: 684311.2625s\n",
            "\titers: 7900, epoch: 1 | loss: 1.0281864\n",
            "\tspeed: 0.1823s/iter; left time: 680042.3303s\n",
            "\titers: 8000, epoch: 1 | loss: 0.9798062\n",
            "\tspeed: 0.1829s/iter; left time: 682304.6857s\n",
            "\titers: 8100, epoch: 1 | loss: 1.0021908\n",
            "\tspeed: 0.1824s/iter; left time: 680523.1415s\n",
            "\titers: 8200, epoch: 1 | loss: 1.0421702\n",
            "\tspeed: 0.1822s/iter; left time: 679520.1394s\n",
            "\titers: 8300, epoch: 1 | loss: 1.0153011\n",
            "\tspeed: 0.1833s/iter; left time: 683602.2275s\n",
            "\titers: 8400, epoch: 1 | loss: 0.9692553\n",
            "\tspeed: 0.1913s/iter; left time: 713408.7183s\n",
            "\titers: 8500, epoch: 1 | loss: 1.0209554\n",
            "\tspeed: 0.1833s/iter; left time: 683713.4261s\n",
            "\titers: 8600, epoch: 1 | loss: 0.9920523\n",
            "\tspeed: 0.1841s/iter; left time: 686764.8813s\n",
            "\titers: 8700, epoch: 1 | loss: 1.0054166\n",
            "\tspeed: 0.1859s/iter; left time: 693158.0217s\n",
            "\titers: 8800, epoch: 1 | loss: 0.9736470\n",
            "\tspeed: 0.1860s/iter; left time: 693559.1755s\n",
            "\titers: 8900, epoch: 1 | loss: 1.0221964\n",
            "\tspeed: 0.1847s/iter; left time: 688827.3447s\n",
            "\titers: 9000, epoch: 1 | loss: 1.0015234\n",
            "\tspeed: 0.1847s/iter; left time: 688790.9317s\n",
            "\titers: 9100, epoch: 1 | loss: 1.0134001\n",
            "\tspeed: 0.1849s/iter; left time: 689500.4786s\n",
            "\titers: 9200, epoch: 1 | loss: 1.0139674\n",
            "\tspeed: 0.1853s/iter; left time: 690839.7238s\n",
            "\titers: 9300, epoch: 1 | loss: 1.0376822\n",
            "\tspeed: 0.1861s/iter; left time: 693921.5961s\n",
            "\titers: 9400, epoch: 1 | loss: 1.0110854\n",
            "\tspeed: 0.1867s/iter; left time: 696007.0990s\n",
            "\titers: 9500, epoch: 1 | loss: 1.0029831\n",
            "\tspeed: 0.1878s/iter; left time: 700113.8499s\n",
            "\titers: 9600, epoch: 1 | loss: 0.9987854\n",
            "\tspeed: 0.1829s/iter; left time: 682107.1465s\n",
            "\titers: 9700, epoch: 1 | loss: 1.0036807\n",
            "\tspeed: 0.1842s/iter; left time: 686873.2140s\n",
            "\titers: 9800, epoch: 1 | loss: 1.0050454\n",
            "\tspeed: 0.1847s/iter; left time: 688520.3127s\n",
            "\titers: 9900, epoch: 1 | loss: 1.0232316\n",
            "\tspeed: 0.1835s/iter; left time: 684123.4101s\n",
            "\titers: 10000, epoch: 1 | loss: 0.9851276\n",
            "\tspeed: 0.1835s/iter; left time: 683967.4089s\n",
            "\titers: 10100, epoch: 1 | loss: 1.0280367\n",
            "\tspeed: 0.1845s/iter; left time: 687978.7617s\n",
            "\titers: 10200, epoch: 1 | loss: 0.9792181\n",
            "\tspeed: 0.1834s/iter; left time: 683774.5676s\n",
            "\titers: 10300, epoch: 1 | loss: 1.0211937\n",
            "\tspeed: 0.1817s/iter; left time: 677268.9676s\n",
            "\titers: 10400, epoch: 1 | loss: 0.9841450\n",
            "\tspeed: 0.1827s/iter; left time: 681195.1266s\n",
            "\titers: 10500, epoch: 1 | loss: 0.9972330\n",
            "\tspeed: 0.1850s/iter; left time: 689772.0100s\n",
            "\titers: 10600, epoch: 1 | loss: 1.0413340\n",
            "\tspeed: 0.1873s/iter; left time: 698169.7252s\n",
            "\titers: 10700, epoch: 1 | loss: 1.0120894\n",
            "\tspeed: 0.1843s/iter; left time: 686837.9414s\n",
            "\titers: 10800, epoch: 1 | loss: 1.0189812\n",
            "\tspeed: 0.1842s/iter; left time: 686610.6735s\n",
            "\titers: 10900, epoch: 1 | loss: 0.9870332\n",
            "\tspeed: 0.1853s/iter; left time: 690665.8398s\n",
            "\titers: 11000, epoch: 1 | loss: 0.9938826\n",
            "\tspeed: 0.1833s/iter; left time: 683325.3782s\n",
            "\titers: 11100, epoch: 1 | loss: 1.0191299\n",
            "\tspeed: 0.1848s/iter; left time: 688670.7655s\n",
            "\titers: 11200, epoch: 1 | loss: 1.0188686\n",
            "\tspeed: 0.1852s/iter; left time: 690118.4407s\n",
            "\titers: 11300, epoch: 1 | loss: 1.0246189\n",
            "\tspeed: 0.1850s/iter; left time: 689508.8388s\n",
            "\titers: 11400, epoch: 1 | loss: 0.9822454\n",
            "\tspeed: 0.1846s/iter; left time: 688057.7891s\n",
            "\titers: 11500, epoch: 1 | loss: 1.0227793\n",
            "\tspeed: 0.1878s/iter; left time: 699869.9427s\n",
            "\titers: 11600, epoch: 1 | loss: 1.0329390\n",
            "\tspeed: 0.1859s/iter; left time: 692731.1659s\n",
            "\titers: 11700, epoch: 1 | loss: 1.0106983\n",
            "\tspeed: 0.1912s/iter; left time: 712366.1869s\n",
            "\titers: 11800, epoch: 1 | loss: 1.0096048\n",
            "\tspeed: 0.1851s/iter; left time: 689941.8270s\n",
            "\titers: 11900, epoch: 1 | loss: 1.0253813\n",
            "\tspeed: 0.1861s/iter; left time: 693394.7322s\n",
            "\titers: 12000, epoch: 1 | loss: 0.9778901\n",
            "\tspeed: 0.1840s/iter; left time: 685648.3534s\n",
            "\titers: 12100, epoch: 1 | loss: 0.9899662\n",
            "\tspeed: 0.1845s/iter; left time: 687575.9111s\n",
            "\titers: 12200, epoch: 1 | loss: 1.0283966\n",
            "\tspeed: 0.1852s/iter; left time: 690224.5844s\n",
            "\titers: 12300, epoch: 1 | loss: 1.0040658\n",
            "\tspeed: 0.1841s/iter; left time: 685886.0078s\n",
            "\titers: 12400, epoch: 1 | loss: 1.0094389\n",
            "\tspeed: 0.1825s/iter; left time: 679783.0672s\n",
            "\titers: 12500, epoch: 1 | loss: 1.0082512\n",
            "\tspeed: 0.1863s/iter; left time: 693945.9837s\n",
            "\titers: 12600, epoch: 1 | loss: 1.0066988\n",
            "\tspeed: 0.1882s/iter; left time: 701127.8394s\n",
            "\titers: 12700, epoch: 1 | loss: 1.0240171\n",
            "\tspeed: 0.1838s/iter; left time: 684649.3358s\n",
            "\titers: 12800, epoch: 1 | loss: 1.0179222\n",
            "\tspeed: 0.1884s/iter; left time: 701845.2703s\n",
            "\titers: 12900, epoch: 1 | loss: 1.0169576\n",
            "\tspeed: 0.1865s/iter; left time: 694771.6948s\n",
            "\titers: 13000, epoch: 1 | loss: 1.0125910\n",
            "\tspeed: 0.1873s/iter; left time: 697725.3044s\n",
            "\titers: 13100, epoch: 1 | loss: 1.0338929\n",
            "\tspeed: 0.1853s/iter; left time: 690289.4119s\n",
            "\titers: 13200, epoch: 1 | loss: 0.9799047\n",
            "\tspeed: 0.1850s/iter; left time: 689102.2709s\n",
            "\titers: 13300, epoch: 1 | loss: 1.0336133\n",
            "\tspeed: 0.1866s/iter; left time: 695104.4988s\n",
            "\titers: 13400, epoch: 1 | loss: 1.0184739\n",
            "\tspeed: 0.1845s/iter; left time: 687314.3291s\n",
            "\titers: 13500, epoch: 1 | loss: 1.0178795\n",
            "\tspeed: 0.1834s/iter; left time: 683135.9274s\n",
            "\titers: 13600, epoch: 1 | loss: 1.0170560\n",
            "\tspeed: 0.1845s/iter; left time: 687184.8662s\n",
            "\titers: 13700, epoch: 1 | loss: 0.9878759\n",
            "\tspeed: 0.1866s/iter; left time: 694825.7669s\n",
            "\titers: 13800, epoch: 1 | loss: 1.0060453\n",
            "\tspeed: 0.1845s/iter; left time: 687313.4938s\n",
            "\titers: 13900, epoch: 1 | loss: 1.0094634\n",
            "\tspeed: 0.1891s/iter; left time: 704243.7264s\n",
            "\titers: 14000, epoch: 1 | loss: 1.0312264\n",
            "\tspeed: 0.1879s/iter; left time: 699792.7707s\n",
            "\titers: 14100, epoch: 1 | loss: 1.0374870\n",
            "\tspeed: 0.1834s/iter; left time: 682989.4002s\n",
            "\titers: 14200, epoch: 1 | loss: 1.0073071\n",
            "\tspeed: 0.1830s/iter; left time: 681516.6718s\n",
            "\titers: 14300, epoch: 1 | loss: 0.9959431\n",
            "\tspeed: 0.1862s/iter; left time: 693243.5122s\n"
          ]
        }
      ],
      "source": [
        " %cd ./S-D-Mamba/\n",
        "!python -u run.py --is_training 1 --root_path ./dataset/dopplerdata/ --data_path BOOMBAPBOOMBAPDemo4.11.23.csv --model_id doppler_96_720 --model S_Mamba --data doppler --features S --seq_len 441000 --pred_len 441000 --e_layers 2 --enc_in 137 --dec_in 137 --c_out 137 --des 'Exp' --d_model 512 --d_ff 512 --itr 1 --target '0'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sKrDCxfth3lK"
      },
      "outputs": [],
      "source": [
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "V100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}